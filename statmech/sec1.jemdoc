# jemdoc: menu{MENU}{lec2.html}, showsource
= Notes from Section 1 (Friday Week 2)

Today we'll go over the 1D Ising model again to make sure we understand the calculational details.

=== Periodic boundary conditions

The reason we like to place particles on a /ring/ ($\sigma_{N+1} = \sigma_1$) rather than on a stick is so that the model now has ``perfect translational symmetry'' -- it looks the same if we slide down all the particles ($j \mapsto j+1$)

=== Interpreting Ising model as lattice gas model
    - We can interpret the two states on each site as
        -- $\sigma_j = +1$ -- particle is present at that site
        -- $\sigma_j = -1$ -- that site is empty
    - Now the external field is a sense of ``chemical potential'' that tells you the amount of energy it costs to create a particle (or to move it from the gas phase to liquid phase)
    - And now the interaction term describes the interaction energy between particles that are clumped together in the liquid phase.
    - This is a /discrete/ model rather than a continuous -- the particles are only at fixed sites

=== Writing Hamiltonian as sum over bonds

The 1D Ising model has hamiltonian
\(
H({\sigma_1, ..., \sigma_N}) = -J \sum_j \sigma_j \sigma{j+1} - h \sigma_j \sigma_j
\)
which we can rewrite as a sum over /bonds/
\(
H({\sigma_1, ..., \sigma_N}) = -J \sum_j E(\sigma_j, \sigma_{j+1})
\)
where the function 
\(
E{\sigma_j, \sigma_{j+1}} = ...
\)
represents the energy of the /bond/ between sites $j$ and $j+1$. 

=== The transfer matrix
Notice now that the Hamiltonian is a /sum of separate terms!/ This means that when we write down the term $e^{-\beta H}$ in the partition function, we get a /product/ of exponentials:
\(
e^{-\beta H} = e^{-\beta E(\sigma_1, \sigma_2) - \beta E(\sigma_2, \sigma 3) - ... - \beta E(\sigma_N, \sigma_1)}
\)
\(
= e^{-\beta E(\sigma_1, \sigma_2)} e^{- \beta E(\sigma_2, \sigma 3)}  ... e^{- \beta E(\sigma_N, \sigma_1)}
\)
Each of the factors in this product depends only on $j$ and $j+1$, so we can call it a /transfer matrix/ with two indices $t_{\sigma_1 \sigma_2}$.

We can interpret the components of the transfer matrix as the Boltzmann factor for the energy of that bond, if the two sites of the bond are $\sigma_1$ and $\sigma_2$:
\(
t_{\sigma_1 \sigma_2} = e^{-\beta E(\sigma_1, \sigma_2)}
\)

- Some more stuff about summing over indices when we calculate the partition function, so that the partition function ends up looking like $Z = \textrm{Tr} [t^N]$...

=== Calculating the magnetization

As we learned in last stat mech class, once we have the partition function, we can find the free energy as
\(
F = -T \log Z,
\)
and then the magnetization as
\(
M = - \frac {\partial F} {\partial h} = \langle \sum_i \sigma_i \rangle
\)

We can also directly find the magnetization by doing the thermal average....

=== Taking limits

On our problem set we consider what happens to the 1D Ising model as $N \to \infty, h \to 0, T \to 0$...

As we take the thermodynamic limit, only the larger eigenvalue of the transfer matrix matters:
\(
    Z = \textrm{Tr} [t^N] = \lambda_+^N + \lambda_-^N = \lambda_+^N \left[1 + \left(\frac{\lambda_-}{\lambda_+}\right)^N \right] \to \lambda_+^N
\)

And so the free energy is
\(
F = ... = - N T \log \lambda_+ =
\)
\(
m = \langle \sigma_j \rangle = ... = \frac 1 \beta \frac{e^{\beta J} \sinh {\beta h}} {\sqrt{e^{2\beta J} \sinh^2(\beta h) + e^{-2 \beta J}}}
\)

The homework asks us about the behavior of $m$ as we take various limits.

- When we take the $h \to 0$ limit FIRST, we can replace $\sinh (\beta h)$ with $\beta h$ and then try to simplify...the top of the fraction goes to 0 so then $m \to 0$...
- When we take the $T \to 0$ limit first, $\beta \to \infty$ in the expression, so the second term on the bottom disappears. Then the bottom of the fraction is just the square root of the square of the top, so the answer is $+1$ if the top of the fraction is positive or $-1$ if it's negative.

Do these effects come up experimentally? It depends on whether the thermal energy $k_B T$ is bigger or if the energy of flipping a spin $h \cdot \sigma$ is bigger... In solid state physics, we tend to see the former...some stuff about whether experimental magnetic fields are uniform or not, and about self-averaging out the field...

The fact that $m=0$ in one of these limits is peculiar to the 1D Ising model. We'll see that for the 2D Ising model the magnetization will be non-zero at zero temperature....

In 1D, there are no phase transitions from the random-spin phase to the aligned-spin phase.

=== Why no phase transitions in 1D?

Remember from the first lecture...the lowest-energy excitations in 1D are ``domain walls'' where all the spins on one side are up and the other side are down. The energy difference is miniscule (just one misaligned pair), but the entropy gain is HUGE (since there's $N$ possible locations for the domain wall), so at any finite temperature, domain wall formation is favorable.

This is the reason why the first limit holds (that is, why $m=0$ when we take $h \to 0$ before $T \to 0$). As the temperature goes to 0 (but remains finite), these domain wall fluctuations mess up any ordering in the spins, so the magnetization remains 0 (disordered).

=== Analogy with 0-D quantum system (spin-half)

The transfer matrix can be written as a 2x2 matrix, which is finite dimensional. We can think of it as related to the Hamiltonian a 0-dimensional spin-half quantum system...

We need to take the matrix log to write the transfer matrix $t$ as an exponential $e^{-\vec{b} \cdot \vec{\tau}}$ (where the exponent is related to the Hamiltonian of the corresponding quantum system)

How do we find this $\vec{b}$?

- Write $\vec{b} = b \hat n$ and it's nice because $(\hat n \cdot \vec{\tau}) = +1$
- Write the exponential as sum of the sinhs and coshs. One contains all the even powers, other contains odd powers.
- The even powers all have $(\hat n \cdot \vec{\tau}) = +1$ whereas the odd powers have $(\hat n \cdot \vec{\tau}) = -1$. So we can separate into sinhs and coshs....
- Anotehr way to see it: Consider the action of the exponentiated matrix on the eigenstates of the matrix. It should get you $e^{b}$ for one eigenstate (pointing the n hat direction) and then $e^{-b}$ for the other eignestate. Then consider the sum on an arbitrary linear combination of those states...

=== The algebra of Pauli Matrices

- The object $\vec{\tau}$ is a vector of Pauli matrices...
- Anti communtation relations, etc...
